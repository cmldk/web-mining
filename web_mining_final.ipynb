{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web-mining-final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebzgjjauDKOj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report\n",
        "\n",
        "def currentTime():\n",
        "  return int(round(time.time() * 1000))\n",
        "\n",
        "start = currentTime()\n",
        "# Load data\n",
        "data_url = \"https://raw.githubusercontent.com/cmldk/web-mining/master/heart_failure_clinical_records_dataset.csv\"\n",
        "_data = pd.read_csv(data_url, sep=\"[;,]\", engine='python')\n",
        "target = _data.iloc[:,-1]\n",
        "data = _data.iloc[:,:-1]\n",
        "\n",
        "# don't need encoding for data\n",
        "print(\"Data Types-----------\")\n",
        "print(_data.dtypes)\n",
        "\n",
        "print(\"\\nNull Values for Columns--------\")\n",
        "print(_data.isnull().sum())\n",
        "\n",
        "# Applying Principal Component Analysis(PCA)\n",
        "pca = PCA(n_components=5)\n",
        "data_pca = pca.fit_transform(data)\n",
        "#print(data_pca)\n",
        "\n",
        "#StandardScaler\n",
        "sc = StandardScaler()\n",
        "scaled_data = sc.fit_transform(data)\n",
        "#print(scaled_data)\n",
        "\n",
        "# Correlation Matrix\n",
        "corr = data.corr()\n",
        "corr_heatmap = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
        "fig = corr_heatmap.get_figure()\n",
        "fig.savefig(\"CorrelationHeatmap.pdf\", bbox_inches='tight')\n",
        "\n",
        "#Exploring data\n",
        "fig2 = plt.figure(figsize=(10,10))\n",
        "sns.distplot(x=data['age'])\n",
        "plt.title('Age Plot')\n",
        "fig2.savefig(\"Age.pdf\",bbox_inches='tight')\n",
        "\n",
        "#Accuracy function\n",
        "def findAccuracy(algo, algo_name, X_train, X_test, y_train, y_test):\n",
        "  start_time = currentTime()\n",
        "  algo.fit(X_train, y_train)\n",
        "  y_pred_train = algo.predict(X_train)\n",
        "  algo_train_score = accuracy_score(y_train, y_pred_train)  # Accuracy score of train set\n",
        "  y_pred_test = algo.predict(X_test)\n",
        "  algo_test_score = accuracy_score(y_test, y_pred_test)  # Accuracy score of test set\n",
        "  passing_time = currentTime() - start_time\n",
        "  passing_times.append(passing_time)\n",
        "  print(algo_name + \" \\nTrain Accuracy : {0} , Test Accuracy : {1} and Passing Time : {2}ms\".format(algo_train_score, algo_test_score, passing_time))\n",
        "  return algo_train_score, algo_test_score\n",
        "\n",
        "# LINEAR CLASSIFICATION TASKS\n",
        "log_reg = LogisticRegression(max_iter=1000) # Logistic Regression Process\n",
        "slp = Perceptron()                          # Single Layer Perceptron Process\n",
        "sgd = SGDClassifier()                       # Stochastic Gradient Descent Classifier\n",
        "\n",
        "# NEURAL NETWORK BASED CLASSIFICATION\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(16,8,4,2), max_iter=1000) # Multi Layer Perceptron Classifier\n",
        "\n",
        "# ENSEMBLE LEARNING BASED CLASSIFICATION\n",
        "bag = BaggingClassifier()                   # Bagging\n",
        "rfc = RandomForestClassifier()              # Random Forest Classifier\n",
        "adb = AdaBoostClassifier()                  # Adaboost\n",
        "\n",
        "# XGBOOST\n",
        "xgboost = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)\n",
        "\n",
        "sorted_dict = []\n",
        "#Plotting the all results of algorithms on 3 different form of data(PCA, Scaled and Normal)\n",
        "for x,t in zip([data_pca, scaled_data, data],[\"PCA\", \"Scaled\", \"Normal\"]):\n",
        "  passing_times = []\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, target, train_size=0.7)  # split data into train and test\n",
        "  print(\"\\n----------------\"+ t + \" Results-------------\")\n",
        "  logistic_train_score, logistic_test_score = findAccuracy(log_reg, \"LOGISTIC REGRESSION\", X_train, X_test, y_train, y_test)\n",
        "  slp_train_score, slp_test_score = findAccuracy(slp, \"SINGLE LAYER PERCEPTRON\", X_train, X_test, y_train, y_test)\n",
        "  sgd_train_score, sgd_test_score = findAccuracy(sgd, \"STOCHASTIC GRADIENT DESCENT CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "  mlp_train_score, mlp_test_score = findAccuracy(mlp, \"MULTI LAYER PERCEPTRON CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "  bag_train_score, bag_test_score = findAccuracy(bag, \"BAGGING CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "  rfc_train_score, rfc_test_score = findAccuracy(rfc, \"RANDOM FOREST CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "  adb_train_score, adb_test_score = findAccuracy(adb, \"ADABOOST CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "  xgb_train_score, xgb_test_score = findAccuracy(xgboost, \"XGBOOST CLASSIFIER\", X_train, X_test, y_train, y_test)\n",
        "\n",
        "  algorithms = [\"Logistic Regression\",\"Single Layer Perceptron\",\"SGD classifier\",\"MLP classifier\",\"Bagging Classifier\",\"Random Forest Classifier\",\"Adaboost Classifier\",\"XGBOOST Classifier\"]\n",
        "  algo_to_name = {log_reg: \"Logistic Regression\",\n",
        "                  slp: \"Single Layer Perceptron\",\n",
        "                  sgd: \"SGD classifier\",\n",
        "                  mlp: \"MLP classifier\",\n",
        "                  bag: \"Bagging Classifier\",\n",
        "                  rfc: \"Random Forest Classifier\",\n",
        "                  adb: \"Adaboost Classifier\",\n",
        "                  xgboost: \"XGBOOST Classifier\"}\n",
        "  train_scores = [logistic_train_score,slp_train_score,sgd_train_score,mlp_train_score,bag_train_score,rfc_train_score,adb_train_score,xgb_train_score]\n",
        "  test_scores = [logistic_test_score,slp_test_score,sgd_test_score,mlp_test_score,bag_test_score,rfc_test_score,adb_test_score, xgb_test_score]\n",
        "  algo_to_test = {log_reg: logistic_test_score,\n",
        "                  slp: slp_test_score,\n",
        "                  sgd: sgd_test_score,\n",
        "                  mlp: mlp_test_score,\n",
        "                  bag: bag_test_score,\n",
        "                  rfc: rfc_test_score,\n",
        "                  adb: adb_test_score,\n",
        "                  xgboost: xgb_test_score,}\n",
        "\n",
        "  fig2 = plt.figure(figsize=(20,5))\n",
        "  ax = fig2.add_subplot(1,2,1)\n",
        "  true_values = []\n",
        "  false_values = []\n",
        "  names = []\n",
        "  sorted_dict = sorted(algo_to_test, key=algo_to_test.get, reverse=True)\n",
        "  for i in range(2):\n",
        "    algo = sorted_dict[i]\n",
        "    names.append(algo_to_name.get(algo))\n",
        "    y_pred = algo.predict(X_test)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    true_values.append(conf_matrix[0][0] + conf_matrix[1][1])\n",
        "    false_values.append(conf_matrix[0][1] + conf_matrix[1][0])\n",
        " \n",
        "  ind = np.arange(len(names))\n",
        "  width = 0.4\n",
        "  ax.barh(ind, false_values, width, color='red', label='False values')\n",
        "  ax.barh(ind + width, true_values, width, color='green', label='True values')\n",
        "  # Remove axes splines \n",
        "  for s in ['top', 'bottom', 'left', 'right']: \n",
        "      ax.spines[s].set_visible(False) \n",
        "  # Remove x, y Ticks \n",
        "  ax.xaxis.set_ticks_position('none') \n",
        "  ax.yaxis.set_ticks_position('none') \n",
        "  # Add padding between axes and labels \n",
        "  ax.xaxis.set_tick_params(pad = 5) \n",
        "  ax.yaxis.set_tick_params(pad = 10) \n",
        "  # Add x, y gridlines \n",
        "  ax.grid(b = True, color ='grey', \n",
        "          linestyle ='-.', linewidth = 0.5, \n",
        "          alpha = 0.2) \n",
        "  for i in ax.patches: \n",
        "    plt.text(i.get_width()+0.2, i.get_y()+0.18,  \n",
        "             str(round((i.get_width()), 2)), \n",
        "             fontsize = 8, fontweight ='bold')\n",
        "  ax.set(yticks=ind + 0.2, yticklabels=names, ylim=[width - 1, len(names)])\n",
        "  title = 'True&False values of 2 Algorithms that have highest test score for {0}'.format(t)\n",
        "  ax.set_title(title, loc ='left')\n",
        "  ax.legend()\n",
        "\n",
        "  fig2.add_subplot(1,2,2)\n",
        "  colors = ['red', 'green', 'yellow', 'orange', 'purple','blue', '#b4b85e', 'violet']\n",
        "  ts = []\n",
        "  for s in test_scores:\n",
        "    ts.append(\"{:.3f}\".format(s))\n",
        "  for i,s in enumerate(test_scores):\n",
        "    plt.scatter(test_scores[i], passing_times[i], color=colors[i], label=algorithms[i])\n",
        "    plt.annotate(ts[i], (test_scores[i], passing_times[i]))\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.grid()\n",
        "  plt.ylabel(\"Passing Times in ms\")\n",
        "  plt.xlabel(\"Accuracy scores\")\n",
        "  plt.title(t)\n",
        "  plt.show()\n",
        "  text = t + \"_Results.pdf\"\n",
        "  fig2.savefig(text, bbox_inches='tight')\n",
        "\n",
        "#Best algorithm results\n",
        "result_prediction = sorted_dict[0].predict(data)\n",
        "result = _data\n",
        "result[\"DEATH_EVENT_pred\"] = result_prediction\n",
        "#classification report\n",
        "classification_report = classification_report(target, result_prediction)\n",
        "print(classification_report)\n",
        "\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.title(\"Test Data\")\n",
        "sns.countplot(result['DEATH_EVENT'])\n",
        "fig.add_subplot(1,2,2)\n",
        "plt.title(\"Predict Data\")\n",
        "sns.countplot(result['DEATH_EVENT_pred'])\n",
        "fig.savefig(\"Prediction_Result.pdf\",bbox_inches='tight')\n",
        "\n",
        "end = currentTime() - start\n",
        "print(\"Total Runtime: {0}sn\".format(end/1000))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}